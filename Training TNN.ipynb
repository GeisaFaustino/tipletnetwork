{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet NN for signature validation using Keras\n",
    "\n",
    "This code is inspired from KinWaiCheuk [github repository](https://github.com/KinWaiCheuk/Triplet-net-keras).\n",
    "For a good intruduction about Triplet net (also know as triplet loss) see [Triplet Loss and Online Triplet Mining in TensorFlow](https://omoindrot.github.io/triplet-loss) by Olivier Moindrot.\n",
    "\n",
    "Here I am using triplet NN to validade signatures. The idea is that:\n",
    "* Two examples of genuine signatures from the same person have their embeddings close together in the embedding space\n",
    "* A genuine signature and a forged one have their embeddings far away.\n",
    "\n",
    "**References:** \n",
    "* [Tensorflow-Signature-Recognition](https://github.com/rmalav15/signature-recognition)\n",
    "* [Triplet Loss - Coursera video](https://www.coursera.org/lecture/convolutional-neural-networks/triplet-loss-HuUtN?utm_source=linkshare&siteID=je6NUbpObpQ-vGHsrqsSjAzy9re5xFJZ7Q&ranEAID=je6NUbpObpQ&utm_content=10&ranMID=40328&ranSiteID=je6NUbpObpQ-vGHsrqsSjAzy9re5xFJZ7Q&utm_campaign=je6NUbpObpQ&utm_medium=partners)\n",
    "* [How to Save and Load Your Keras Deep Learning Model](https://machinelearningmastery.com/save-load-keras-deep-learning-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and extracting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://cedar.buffalo.edu/NIJ/data/signatures.rar -q --show-progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unrar x signatures.rar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 2.1.5\n",
      "Tensorflow 1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, Dropout, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Keras', keras.__version__)\n",
    "print('Tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7438340513098088444\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16117478182665119839\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1425896877825667038\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11281927373\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2381110276871932694\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 7fb7:00:00.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if keras(>=2.1.1) is using GPU:\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (128, 128)\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sign_path = 'signatures/full_org/'\n",
    "for_sign_path = 'signatures/full_forg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sign = pd.read_csv( 'signatures/X_train.csv' )\n",
    "testing_sign = pd.read_csv( 'signatures/X_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anchor</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original_14_17.png</td>\n",
       "      <td>original_14_1.png</td>\n",
       "      <td>forgeries_14_1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original_6_4.png</td>\n",
       "      <td>original_6_5.png</td>\n",
       "      <td>forgeries_6_5.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original_17_8.png</td>\n",
       "      <td>original_17_12.png</td>\n",
       "      <td>forgeries_17_12.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original_42_3.png</td>\n",
       "      <td>original_42_14.png</td>\n",
       "      <td>forgeries_42_14.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original_1_18.png</td>\n",
       "      <td>original_1_10.png</td>\n",
       "      <td>forgeries_1_10.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Anchor            Positive             Negative\n",
       "0  original_14_17.png   original_14_1.png   forgeries_14_1.png\n",
       "1    original_6_4.png    original_6_5.png    forgeries_6_5.png\n",
       "2   original_17_8.png  original_17_12.png  forgeries_17_12.png\n",
       "3   original_42_3.png  original_42_14.png  forgeries_42_14.png\n",
       "4   original_1_18.png   original_1_10.png   forgeries_1_10.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_sign.shape: (20341, 3)\n",
      "testing_sign.shape: (10019, 3)\n"
     ]
    }
   ],
   "source": [
    "print( 'training_sign.shape:', training_sign.shape )\n",
    "print( 'testing_sign.shape:', testing_sign.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method for processing input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_image( image_path, image_shape ):\n",
    "    '''\n",
    "    Method for generating input image\n",
    "    Args:\n",
    "        image_path - full path for image\n",
    "        image_shape - tuple (w, h) with new image width and hight\n",
    "    Return:\n",
    "        processed_image - a binary image with size (w, h)\n",
    "    '''\n",
    "    # Read image as grayscale\n",
    "    image = cv2.imread( image_path, cv2.IMREAD_GRAYSCALE )\n",
    "    \n",
    "    # Binarize image through Otsu's thresholding. \n",
    "    # Background will be back and signature will be white.\n",
    "    _, image_bin = cv2.threshold( image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU )\n",
    "    \n",
    "    # Compute signature bounding box\n",
    "    points = cv2.findNonZero( image_bin )\n",
    "    x, y, w, h = cv2.boundingRect( points )\n",
    "    \n",
    "    # Crop image according to boundingbox\n",
    "    proc_image = image_bin[y:y+h, x:x+w]\n",
    "    \n",
    "    resized_image = cv2.resize( proc_image, image_shape )\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating images for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_array( images_name_df ):\n",
    "    \n",
    "    '''\n",
    "    Method for generating a array of triplet images (anchor, positive, negative)\n",
    "    '''\n",
    "    # List of triplet signature images (anchor, positive, negative)\n",
    "    images_list = [] \n",
    "\n",
    "    for index, row in tqdm( images_name_df.iterrows() ):\n",
    "        \n",
    "        anchor = processing_image( gen_sign_path + row['Anchor'], IMAGE_SHAPE )   \n",
    "        positive = processing_image( gen_sign_path + row['Positive'], IMAGE_SHAPE )   \n",
    "        negative = processing_image( for_sign_path + row['Negative'], IMAGE_SHAPE )   \n",
    "    \n",
    "        images_list.append( (anchor/255., positive/255., negative/255.) )\n",
    "    \n",
    "    return np.asarray( images_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20341it [03:19, 101.77it/s]\n",
      "10019it [01:35, 104.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = generate_images_array( training_sign )\n",
    "X_test = generate_images_array( testing_sign )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (20341, 3, 128, 128)\n",
      "X_test.shape: (10019, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print( 'X_train.shape:', X_train.shape )\n",
    "print( 'X_test.shape:', X_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing triplet loss\n",
    "\n",
    "$L = max( d(a,p) − d(a,n) + margin, 0 )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss( labels, embedings, marging = 0.4 ):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Args:\n",
    "        labels -- true labels, required when you define a loss in Keras. In fact, we don't need it in this function.\n",
    "        embedings -- python list containing three objects:\n",
    "                  anchor   -- the embedings for the anchor data\n",
    "                  positive -- the embedings for the positive data (similar to anchor)\n",
    "                  negative -- the embedings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    lenght = embedings.shape.as_list()[-1]\n",
    "    \n",
    "    anchor   = embedings[:, 0               : int(lenght*1/3) ]\n",
    "    positive = embedings[:, int(lenght*1/3) : int(lenght*2/3) ]\n",
    "    negative = embedings[:, int(lenght*2/3) : int(lenght*3/3) ]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    positive_dist = K.sum( K.square(anchor - positive), axis = 1 )\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    negative_dist = K.sum( K.square(anchor - negative), axis = 1 )\n",
    "\n",
    "    # compute loss\n",
    "    loss = K.maximum( (positive_dist - negative_dist + marging), 0.0 )\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creading network and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network( input_dimensions ):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    embedding_size = 128\n",
    "    input_img_shape = ( input_dimensions[0], input_dimensions[1], input_dimensions[2] )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add( Conv2D( 256, kernel_size = 7, activation = 'relu', input_shape = input_img_shape, padding = 'same', name = 'conv1') )\n",
    "    model.add( MaxPooling2D( pool_size = (2,2), strides = (2,2), padding = 'same', name = 'pool1') )\n",
    "    model.add( Conv2D( 512, kernel_size = 5, activation = 'relu', padding = 'same', name = 'conv2') )\n",
    "    model.add( MaxPooling2D( pool_size = (2,2), strides = (2,2), padding = 'same', name = 'pool2') )\n",
    "    model.add( Flatten( name = 'flatten') )\n",
    "    model.add( Dense( embedding_size, name = 'embeddings') )\n",
    "    model.add( BatchNormalization() )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 128, 128, 256)     12800     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 64, 64, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 524288)            0         \n",
      "_________________________________________________________________\n",
      "embeddings (Dense)           (None, 128)               67108992  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "=================================================================\n",
      "Total params: 70,399,616\n",
      "Trainable params: 70,399,360\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "anchor_input   = Input( (IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1, ), name = 'anchor_input' )\n",
    "positive_input = Input( (IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1, ), name = 'positive_input' )\n",
    "negative_input = Input( (IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1, ), name = 'negative_input' )\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "shared_dnn = create_base_network( [IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1,] )\n",
    "\n",
    "anchor_embeding   = shared_dnn(anchor_input)\n",
    "positive_embeding = shared_dnn(positive_input)\n",
    "negative_embeding = shared_dnn(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate( [anchor_embeding, positive_embeding, negative_embeding], \n",
    "                             axis=-1, \n",
    "                             name = 'merged_layer' )\n",
    "\n",
    "model = Model( inputs = [anchor_input, positive_input, negative_input], outputs = merged_vector )\n",
    "model.compile( loss = triplet_loss, optimizer = adam_optim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          70399616    anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 384)          0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "                                                                 sequential[3][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,399,616\n",
      "Trainable params: 70,399,360\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20341 samples, validate on 10019 samples\n",
      "Epoch 1/50\n",
      "20341/20341 [==============================] - 1041s 51ms/step - loss: 1.0467 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "20341/20341 [==============================] - 971s 48ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "20341/20341 [==============================] - 972s 48ms/step - loss: 0.0210 - val_loss: 0.0748\n",
      "Epoch 4/50\n",
      "20341/20341 [==============================] - 970s 48ms/step - loss: 0.0191 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      " 1900/20341 [=>............................] - ETA: 12:31 - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20341/20341 [==============================] - 961s 47ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "20341/20341 [==============================] - 961s 47ms/step - loss: 0.0095 - val_loss: 0.0151\n",
      "Epoch 12/50\n",
      "20341/20341 [==============================] - 961s 47ms/step - loss: 0.0173 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "18850/20341 [==========================>...] - ETA: 1:00 - loss: 5.8850e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20341/20341 [==============================] - 957s 47ms/step - loss: 0.0056 - val_loss: 0.0101\n",
      "Epoch 17/50\n",
      "20341/20341 [==============================] - 956s 47ms/step - loss: 9.3080e-04 - val_loss: 0.0027\n",
      "Epoch 18/50\n",
      "20341/20341 [==============================] - 956s 47ms/step - loss: 1.0414e-04 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "20341/20341 [==============================] - 956s 47ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "20341/20341 [==============================] - 955s 47ms/step - loss: 0.0023 - val_loss: 0.0108\n",
      "Epoch 21/50\n",
      " 6250/20341 [========>.....................] - ETA: 9:27 - loss: 0.0025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20341/20341 [==============================] - 953s 47ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "20341/20341 [==============================] - 952s 47ms/step - loss: 6.9581e-04 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "20341/20341 [==============================] - 952s 47ms/step - loss: 7.8438e-04 - val_loss: 9.7883e-04\n",
      "Epoch 29/50\n",
      "20341/20341 [==============================] - 951s 47ms/step - loss: 5.4921e-04 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      " 8950/20341 [============>.................] - ETA: 7:37 - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20341/20341 [==============================] - 952s 47ms/step - loss: 0.0075 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "20341/20341 [==============================] - 951s 47ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "20341/20341 [==============================] - 951s 47ms/step - loss: 4.7541e-04 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "20341/20341 [==============================] - 950s 47ms/step - loss: 3.2389e-04 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      " 7600/20341 [==========>...................] - ETA: 8:30 - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20341/20341 [==============================] - 951s 47ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "20341/20341 [==============================] - 950s 47ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "20341/20341 [==============================] - 949s 47ms/step - loss: 2.7959e-04 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "20341/20341 [==============================] - 949s 47ms/step - loss: 5.8876e-04 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      " 5075/20341 [======>.......................] - ETA: 10:11 - loss: 3.9954e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_train = X_train[:,0,:].reshape(-1, IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1)\n",
    "P_train = X_train[:,1,:].reshape(-1, IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1)\n",
    "N_train = X_train[:,2,:].reshape(-1, IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1)\n",
    "\n",
    "A_test = X_test[:,0,:].reshape(-1, IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1)\n",
    "P_test = X_test[:,1,:].reshape(-1, IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1)\n",
    "N_test = X_test[:,2,:].reshape(-1, IMAGE_SHAPE[0], IMAGE_SHAPE[1], 1)\n",
    "\n",
    "y_dummy_train = np.empty( (A_train.shape[0], 300) )\n",
    "y_dummy_test  = np.empty( (A_test.shape[0], 1) )\n",
    "\n",
    "H = model.fit( x = [A_train, P_train, N_train],\n",
    "               y = y_dummy_train,\n",
    "               validation_data = ( [A_test, P_test, N_test], y_dummy_test ), \n",
    "               batch_size = BATCH_SIZE, \n",
    "               epochs = EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(H.history['loss'], label='training loss')\n",
    "plt.plot(H.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.title('Train/validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
